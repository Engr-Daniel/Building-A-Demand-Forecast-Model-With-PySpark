{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a711e2f",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d563adcb",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 12,
    "lastExecutedAt": 1711379809343,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from pyspark.sql import SparkSession\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\nfrom pyspark.sql.types import StringType, DoubleType\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.sql.functions import col, dayofmonth, month, year,  to_date, to_timestamp, weekofyear, dayofweek"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import col, dayofmonth, month, year,  to_date, to_timestamp, weekofyear, dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86f17667",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 436,
    "lastExecutedAt": 1711379809779,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Initialize SparkSession\nspark = SparkSession.builder.appName(\"ModelComparison\").getOrCreate()\n\n# Importing sales data\nsales_data = spark.read.csv(\n    \"Online Retail.csv\", header=True, inferSchema=True, sep=\",\")\n\n# Convert InvoiceDate to datetime \nsales_data = sales_data.withColumn(\"InvoiceDate\", to_date(\n    to_timestamp(col(\"InvoiceDate\"), \"d/M/yyyy H:mm\")))\n\n# Aggregate data into daily intervals\ndaily_sales_data = sales_data.groupBy(\"Country\", \"StockCode\", \"InvoiceDate\", \"Year\", \"Month\", \"Day\", \"Week\", \"DayOfWeek\").agg({\"Quantity\": \"sum\",                                                                                                           \"UnitPrice\": \"avg\"})\n# Rename the target column\ndaily_sales_data = daily_sales_data.withColumnRenamed(\n    \"sum(Quantity)\", \"Quantity\")",
    "outputsMetadata": {
     "0": {
      "height": 77,
      "type": "stream"
     },
     "1": {
      "height": 57,
      "type": "stream"
     },
     "2": {
      "height": 37,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"ModelComparison\").getOrCreate()\n",
    "\n",
    "# Importing sales data\n",
    "sales_data = spark.read.csv(\n",
    "    \"Online Retail.csv\", header=True, inferSchema=True, sep=\",\")\n",
    "\n",
    "# Convert InvoiceDate to datetime \n",
    "sales_data = sales_data.withColumn(\"InvoiceDate\", to_date(\n",
    "    to_timestamp(col(\"InvoiceDate\"), \"d/M/yyyy H:mm\")))\n",
    "\n",
    "# Aggregate data into daily intervals\n",
    "daily_sales_data = sales_data.groupBy(\"Country\", \"StockCode\", \"InvoiceDate\", \"Year\", \"Month\", \"Day\", \"Week\", \"DayOfWeek\").agg({\"Quantity\": \"sum\",                                                                                                           \"UnitPrice\": \"avg\"})\n",
    "# Rename the target column\n",
    "daily_sales_data = daily_sales_data.withColumnRenamed(\n",
    "    \"sum(Quantity)\", \"Quantity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4b3457b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1985,
    "lastExecutedAt": 1711379811766,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "split_date_train_test = \"2011-09-25\"\n\n# Creating the train and test datasets\ntrain_data = daily_sales_data.filter(\n    col(\"InvoiceDate\") <= split_date_train_test)\n\ntest_data = daily_sales_data.filter(\n    col(\"InvoiceDate\") > split_date_train_test)\n\npd_daily_train_data = train_data.toPandas()\npd_daily_train_data.head()",
    "outputsMetadata": {
     "0": {
      "height": 211,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "data": {
         "Country": [
          "United Kingdom",
          "France",
          "United Kingdom",
          "United Kingdom",
          "Norway"
         ],
         "Day": [
          12,
          12,
          12,
          12,
          12
         ],
         "DayOfWeek": [
          1,
          1,
          1,
          1,
          1
         ],
         "InvoiceDate": [
          "2010-01-12T00:00:00.000",
          "2010-01-12T00:00:00.000",
          "2010-01-12T00:00:00.000",
          "2010-01-12T00:00:00.000",
          "2010-01-12T00:00:00.000"
         ],
         "Month": [
          1,
          1,
          1,
          1,
          1
         ],
         "Quantity": [
          3,
          24,
          12,
          16,
          12
         ],
         "StockCode": [
          "22912",
          "22659",
          "21544",
          "21098",
          "85150"
         ],
         "Week": [
          2,
          2,
          2,
          2,
          2
         ],
         "Year": [
          2010,
          2010,
          2010,
          2010,
          2010
         ],
         "avg(UnitPrice)": [
          4.95,
          1.95,
          0.85,
          1.25,
          2.55
         ],
         "index": [
          0,
          1,
          2,
          3,
          4
         ]
        },
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "Country",
           "type": "string"
          },
          {
           "name": "StockCode",
           "type": "string"
          },
          {
           "name": "InvoiceDate",
           "type": "string"
          },
          {
           "name": "Year",
           "type": "integer"
          },
          {
           "name": "Month",
           "type": "integer"
          },
          {
           "name": "Day",
           "type": "integer"
          },
          {
           "name": "Week",
           "type": "integer"
          },
          {
           "name": "DayOfWeek",
           "type": "integer"
          },
          {
           "name": "avg(UnitPrice)",
           "type": "number"
          },
          {
           "name": "Quantity",
           "type": "integer"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 5,
       "truncation_type": null
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>avg(UnitPrice)</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>22912</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>22659</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>21544</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>21098</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norway</td>\n",
       "      <td>85150</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country StockCode InvoiceDate  ...  DayOfWeek  avg(UnitPrice)  Quantity\n",
       "0  United Kingdom     22912  2010-01-12  ...          1            4.95         3\n",
       "1          France     22659  2010-01-12  ...          1            1.95        24\n",
       "2  United Kingdom     21544  2010-01-12  ...          1            0.85        12\n",
       "3  United Kingdom     21098  2010-01-12  ...          1            1.25        16\n",
       "4          Norway     85150  2010-01-12  ...          1            2.55        12\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_date_train_test = \"2011-09-25\"\n",
    "\n",
    "# Creating the train and test datasets\n",
    "train_data = daily_sales_data.filter(\n",
    "    col(\"InvoiceDate\") <= split_date_train_test)\n",
    "\n",
    "test_data = daily_sales_data.filter(\n",
    "    col(\"InvoiceDate\") > split_date_train_test)\n",
    "\n",
    "pd_daily_train_data = train_data.toPandas()\n",
    "pd_daily_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fbbb8f-df87-45dd-a209-69c073013927",
   "metadata": {},
   "source": [
    "## Define a fuction to evaluate each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "502e6234-ff4e-45af-ba4c-b9b0e9ff3062",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 59,
    "lastExecutedAt": 1711379811825,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n\ndef train_and_evaluate_regression_model(train_data, test_data, model_type):\n    \n    # Creating indexer for categorical columns\n    country_indexer = StringIndexer(\n        inputCol=\"Country\", outputCol=\"CountryIndex\").setHandleInvalid(\"keep\")\n    stock_code_indexer = StringIndexer(\n        inputCol=\"StockCode\", outputCol=\"StockCodeIndex\").setHandleInvalid(\"keep\")\n    \n    # Define feature columns\n    feature_cols = [\"CountryIndex\", \"StockCodeIndex\", \"Month\", \"Year\", \"DayOfWeek\", \"Day\", \"Week\"]\n\n    # Assemble features\n    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n\n    # Initialize the specified regression model\n    if model_type == \"LinearRegression\":\n        model = LinearRegression(labelCol=\"Quantity\", featuresCol=\"features\")\n    elif model_type == \"DecisionTree\":\n        model = DecisionTreeRegressor(labelCol=\"Quantity\", featuresCol=\"features\", maxBins=4000)\n    elif model_type == \"RandomForest\":\n        model = RandomForestRegressor(labelCol=\"Quantity\", featuresCol=\"features\", maxBins=4000)\n    elif model_type == \"GBT\":\n        model = GBTRegressor(labelCol=\"Quantity\", featuresCol=\"features\", maxBins=4000)\n    else:\n        raise ValueError(\"Invalid model type. Choose from 'LinearRegression', 'DecisionTree', 'RandomForest', or 'GBT'.\")\n\n    # Create a pipeline for the model\n    pipeline = Pipeline(stages=[country_indexer, stock_code_indexer, assembler, model])\n\n    # Train the model\n    trained_model = pipeline.fit(train_data)\n\n    # Make predictions on test data\n    test_predictions = trained_model.transform(test_data)\n\n    # Initialize evaluators\n    evaluators = {\n        \"rmse\": RegressionEvaluator(labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"rmse\"),\n        \"r2\": RegressionEvaluator(labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"r2\"),\n        \"mse\": RegressionEvaluator(labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"mse\"),\n        \"mae\": RegressionEvaluator(labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"mae\")\n    }\n\n    # Initialize results dictionary\n    results = {}\n\n    # Obtain evaluation metrics\n    for metric, evaluator in evaluators.items():\n        results[metric] = evaluator.evaluate(test_predictions)\n\n    return results\n"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "\n",
    "def train_and_evaluate_regression_model(train_data, test_data, model_type):\n",
    "    \n",
    "    # Creating indexer for categorical columns\n",
    "    country_indexer = StringIndexer(\n",
    "        inputCol=\"Country\", outputCol=\"CountryIndex\").setHandleInvalid(\"keep\")\n",
    "    stock_code_indexer = StringIndexer(\n",
    "        inputCol=\"StockCode\", outputCol=\"StockCodeIndex\").setHandleInvalid(\"keep\")\n",
    "    \n",
    "    # Define feature columns\n",
    "    feature_cols = [\"CountryIndex\", \"StockCodeIndex\", \"Month\", \"Year\", \"DayOfWeek\", \"Day\", \"Week\"]\n",
    "\n",
    "    # Assemble features\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "    # Initialize the specified regression model\n",
    "    if model_type == \"LinearRegression\":\n",
    "        model = LinearRegression(labelCol=\"Quantity\", featuresCol=\"features\")\n",
    "    elif model_type == \"DecisionTree\":\n",
    "        model = DecisionTreeRegressor(labelCol=\"Quantity\", featuresCol=\"features\", maxBins=4000)\n",
    "    elif model_type == \"RandomForest\":\n",
    "        model = RandomForestRegressor(labelCol=\"Quantity\", featuresCol=\"features\", maxBins=4000)\n",
    "    elif model_type == \"GBT\":\n",
    "        model = GBTRegressor(labelCol=\"Quantity\", featuresCol=\"features\", maxBins=4000)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose from 'LinearRegression', 'DecisionTree', 'RandomForest', or 'GBT'.\")\n",
    "\n",
    "    # Create a pipeline for the model\n",
    "    pipeline = Pipeline(stages=[country_indexer, stock_code_indexer, assembler, model])\n",
    "\n",
    "    # Train the model\n",
    "    trained_model = pipeline.fit(train_data)\n",
    "\n",
    "    # Make predictions on test data\n",
    "    test_predictions = trained_model.transform(test_data)\n",
    "\n",
    "    # Initialize evaluators\n",
    "    evaluators = {\n",
    "        \"rmse\": RegressionEvaluator(labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "        \"r2\": RegressionEvaluator(labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"r2\"),\n",
    "        \"mse\": RegressionEvaluator(labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"mse\"),\n",
    "        \"mae\": RegressionEvaluator(labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "    }\n",
    "\n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "\n",
    "    # Obtain evaluation metrics\n",
    "    for metric, evaluator in evaluators.items():\n",
    "        results[metric] = evaluator.evaluate(test_predictions)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "474db4fd-d578-4417-a6d2-5e5f8e6f3d3c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 40910,
    "lastExecutedAt": 1711379852736,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\n\n# Initialize an empty dictionary to store evaluation results\nevaluation_results_dict = {}\n\n# Define model types\nmodel_types = [\"RandomForest\", \"GBT\", \"LinearRegression\", \"DecisionTree\"]\n\n# Loop through each model type\nfor model_type in model_types:\n    # Assuming train_and_evaluate_regression_model returns a dictionary of evaluation results\n    evaluation_results = train_and_evaluate_regression_model(train_data, test_data, model_type)\n    # Store evaluation results in the dictionary\n    evaluation_results_dict[model_type] = evaluation_results\n\n# Create a DataFrame from the dictionary\ndf = pd.DataFrame(evaluation_results_dict)\n\ndf\n",
    "outputsMetadata": {
     "0": {
      "height": 77,
      "type": "stream"
     },
     "1": {
      "height": 37,
      "type": "stream"
     },
     "2": {
      "height": 442,
      "type": "stream"
     },
     "3": {
      "height": 170,
      "type": "dataFrame"
     },
     "4": {
      "height": 57,
      "type": "stream"
     },
     "5": {
      "height": 170,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/25 15:16:54 WARN DAGScheduler: Broadcasting large task binary with size 1615.0 KiB\n",
      "24/03/25 15:16:55 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/25 15:17:04 WARN DAGScheduler: Broadcasting large task binary with size 1002.8 KiB\n",
      "24/03/25 15:17:04 WARN DAGScheduler: Broadcasting large task binary with size 1083.2 KiB\n",
      "24/03/25 15:17:04 WARN DAGScheduler: Broadcasting large task binary with size 1122.6 KiB\n",
      "24/03/25 15:17:04 WARN DAGScheduler: Broadcasting large task binary with size 1123.5 KiB\n",
      "24/03/25 15:17:05 WARN DAGScheduler: Broadcasting large task binary with size 1192.0 KiB\n",
      "24/03/25 15:17:05 WARN DAGScheduler: Broadcasting large task binary with size 1226.0 KiB\n",
      "24/03/25 15:17:05 WARN DAGScheduler: Broadcasting large task binary with size 1296.5 KiB\n",
      "24/03/25 15:17:05 WARN DAGScheduler: Broadcasting large task binary with size 1333.6 KiB\n",
      "24/03/25 15:17:05 WARN DAGScheduler: Broadcasting large task binary with size 1334.5 KiB\n",
      "24/03/25 15:17:05 WARN DAGScheduler: Broadcasting large task binary with size 1365.4 KiB\n",
      "24/03/25 15:17:05 WARN DAGScheduler: Broadcasting large task binary with size 1451.4 KiB\n",
      "24/03/25 15:17:06 WARN DAGScheduler: Broadcasting large task binary with size 1499.5 KiB\n",
      "24/03/25 15:17:06 WARN DAGScheduler: Broadcasting large task binary with size 1500.0 KiB\n",
      "24/03/25 15:17:06 WARN DAGScheduler: Broadcasting large task binary with size 1556.8 KiB\n",
      "24/03/25 15:17:06 WARN DAGScheduler: Broadcasting large task binary with size 1606.3 KiB\n",
      "24/03/25 15:17:06 WARN DAGScheduler: Broadcasting large task binary with size 1669.3 KiB\n",
      "24/03/25 15:17:06 WARN DAGScheduler: Broadcasting large task binary with size 1712.4 KiB\n",
      "24/03/25 15:17:07 WARN DAGScheduler: Broadcasting large task binary with size 1712.9 KiB\n",
      "24/03/25 15:17:07 WARN DAGScheduler: Broadcasting large task binary with size 1780.4 KiB\n",
      "24/03/25 15:17:07 WARN DAGScheduler: Broadcasting large task binary with size 1829.0 KiB\n",
      "24/03/25 15:17:07 WARN DAGScheduler: Broadcasting large task binary with size 1887.4 KiB\n",
      "24/03/25 15:17:07 WARN DAGScheduler: Broadcasting large task binary with size 1992.6 KiB\n",
      "24/03/25 15:17:07 WARN DAGScheduler: Broadcasting large task binary with size 1993.1 KiB\n",
      "24/03/25 15:17:08 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/03/25 15:17:08 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "24/03/25 15:17:08 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/03/25 15:17:08 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/03/25 15:17:08 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/03/25 15:17:08 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/03/25 15:17:09 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/03/25 15:17:09 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/03/25 15:17:09 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "24/03/25 15:17:09 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "24/03/25 15:17:09 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "24/03/25 15:17:10 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/03/25 15:17:10 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/03/25 15:17:10 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/03/25 15:17:10 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/03/25 15:17:10 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/03/25 15:17:11 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "24/03/25 15:17:11 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/03/25 15:17:11 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/03/25 15:17:11 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/03/25 15:17:12 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "24/03/25 15:17:12 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "24/03/25 15:17:12 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "24/03/25 15:17:12 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/03/25 15:17:13 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/03/25 15:17:13 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "24/03/25 15:17:13 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/03/25 15:17:13 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/03/25 15:17:13 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "24/03/25 15:17:14 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "24/03/25 15:17:14 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/03/25 15:17:14 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/03/25 15:17:14 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/03/25 15:17:15 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/03/25 15:17:15 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/03/25 15:17:15 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "24/03/25 15:17:15 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "24/03/25 15:17:16 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "24/03/25 15:17:16 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "24/03/25 15:17:16 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "24/03/25 15:17:16 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "24/03/25 15:17:17 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "24/03/25 15:17:17 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/03/25 15:17:17 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/03/25 15:17:17 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/03/25 15:17:18 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/03/25 15:17:18 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/03/25 15:17:18 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/03/25 15:17:18 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/03/25 15:17:19 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/03/25 15:17:19 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/03/25 15:17:19 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/03/25 15:17:19 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "24/03/25 15:17:20 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "24/03/25 15:17:20 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "24/03/25 15:17:20 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "24/03/25 15:17:21 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "24/03/25 15:17:21 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "24/03/25 15:17:26 WARN Instrumentation: [7d4c5225] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "data": {
         "DecisionTree": [
          14.9437163983,
          0.3074579399,
          223.3146597924,
          8.9403676593
         ],
         "GBT": [
          18.5917130698,
          -0.0719332368,
          345.6517948704,
          11.2921990978
         ],
         "LinearRegression": [
          17.8638189073,
          0.0103593278,
          319.1160259519,
          11.5017119241
         ],
         "RandomForest": [
          15.2778357875,
          0.2761433041,
          233.4122663495,
          9.4025119876
         ],
         "index": [
          "rmse",
          "r2",
          "mse",
          "mae"
         ]
        },
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "string"
          },
          {
           "name": "RandomForest",
           "type": "number"
          },
          {
           "name": "GBT",
           "type": "number"
          },
          {
           "name": "LinearRegression",
           "type": "number"
          },
          {
           "name": "DecisionTree",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 4,
       "truncation_type": null
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>GBT</th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>15.277836</td>\n",
       "      <td>18.591713</td>\n",
       "      <td>17.863819</td>\n",
       "      <td>14.943716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.276143</td>\n",
       "      <td>-0.071933</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.307458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>233.412266</td>\n",
       "      <td>345.651795</td>\n",
       "      <td>319.116026</td>\n",
       "      <td>223.314660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>9.402512</td>\n",
       "      <td>11.292199</td>\n",
       "      <td>11.501712</td>\n",
       "      <td>8.940368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RandomForest         GBT  LinearRegression  DecisionTree\n",
       "rmse     15.277836   18.591713         17.863819     14.943716\n",
       "r2        0.276143   -0.071933          0.010359      0.307458\n",
       "mse     233.412266  345.651795        319.116026    223.314660\n",
       "mae       9.402512   11.292199         11.501712      8.940368"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty dictionary to store evaluation results\n",
    "evaluation_results_dict = {}\n",
    "\n",
    "# Define model types\n",
    "model_types = [\"RandomForest\", \"GBT\", \"LinearRegression\", \"DecisionTree\"]\n",
    "\n",
    "# Loop through each model type\n",
    "for model_type in model_types:\n",
    "    # Assuming train_and_evaluate_regression_model returns a dictionary of evaluation results\n",
    "    evaluation_results = train_and_evaluate_regression_model(train_data, test_data, model_type)\n",
    "    # Store evaluation results in the dictionary\n",
    "    evaluation_results_dict[model_type] = evaluation_results\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(evaluation_results_dict)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a86c6f2-d9e2-4091-b900-68294ea5b99c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 58,
    "lastExecutedAt": 1711379852794,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "best_model = df.transpose()\nbest_model = best_model.sort_values(\"mae\")\nbest_model",
    "outputsMetadata": {
     "0": {
      "height": 170,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "data": {
         "index": [
          "DecisionTree",
          "RandomForest",
          "GBT",
          "LinearRegression"
         ],
         "mae": [
          8.9403676593,
          9.4025119876,
          11.2921990978,
          11.5017119241
         ],
         "mse": [
          223.3146597924,
          233.4122663495,
          345.6517948704,
          319.1160259519
         ],
         "r2": [
          0.3074579399,
          0.2761433041,
          -0.0719332368,
          0.0103593278
         ],
         "rmse": [
          14.9437163983,
          15.2778357875,
          18.5917130698,
          17.8638189073
         ]
        },
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "string"
          },
          {
           "name": "rmse",
           "type": "number"
          },
          {
           "name": "r2",
           "type": "number"
          },
          {
           "name": "mse",
           "type": "number"
          },
          {
           "name": "mae",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 4,
       "truncation_type": null
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>14.943716</td>\n",
       "      <td>0.307458</td>\n",
       "      <td>223.314660</td>\n",
       "      <td>8.940368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>15.277836</td>\n",
       "      <td>0.276143</td>\n",
       "      <td>233.412266</td>\n",
       "      <td>9.402512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBT</th>\n",
       "      <td>18.591713</td>\n",
       "      <td>-0.071933</td>\n",
       "      <td>345.651795</td>\n",
       "      <td>11.292199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>17.863819</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>319.116026</td>\n",
       "      <td>11.501712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       rmse        r2         mse        mae\n",
       "DecisionTree      14.943716  0.307458  223.314660   8.940368\n",
       "RandomForest      15.277836  0.276143  233.412266   9.402512\n",
       "GBT               18.591713 -0.071933  345.651795  11.292199\n",
       "LinearRegression  17.863819  0.010359  319.116026  11.501712"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = df.transpose()\n",
    "best_model = best_model.sort_values(\"mae\")\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89af66-8a95-4708-95ee-c6b341822f56",
   "metadata": {},
   "source": [
    "Hence, the best model in performance is Decision Tree though higher computational cost than RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8176924-03b1-4748-9ad2-64ab48916ba5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2121,
    "lastExecutedAt": 1711379854915,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from pyspark.ml.regression import DecisionTreeRegressor\n\n# Creating indexer for categorical columns\ncountry_indexer = StringIndexer(\n    inputCol=\"Country\", outputCol=\"CountryIndex\").setHandleInvalid(\"keep\")\nstock_code_indexer = StringIndexer(\n    inputCol=\"StockCode\", outputCol=\"StockCodeIndex\").setHandleInvalid(\"keep\")\n\n# Selectiong features columns\nfeature_cols = [\"CountryIndex\", \"StockCodeIndex\", \"Month\", \"Year\",\n                \"DayOfWeek\", \"Day\", \"Week\"]\n\n# Using vector assembler to combine features\nassembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n\nbest_model = DecisionTreeRegressor(labelCol=\"Quantity\", featuresCol=\"features\", maxBins=4000)\n\n# Create a pipeline for staging the processes\npipeline = Pipeline(stages=[country_indexer, stock_code_indexer, assembler, best_model])\n\n# Training the model\nmodel = pipeline.fit(train_data)"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "# Creating indexer for categorical columns\n",
    "country_indexer = StringIndexer(\n",
    "    inputCol=\"Country\", outputCol=\"CountryIndex\").setHandleInvalid(\"keep\")\n",
    "stock_code_indexer = StringIndexer(\n",
    "    inputCol=\"StockCode\", outputCol=\"StockCodeIndex\").setHandleInvalid(\"keep\")\n",
    "\n",
    "# Selectiong features columns\n",
    "feature_cols = [\"CountryIndex\", \"StockCodeIndex\", \"Month\", \"Year\",\n",
    "                \"DayOfWeek\", \"Day\", \"Week\"]\n",
    "\n",
    "# Using vector assembler to combine features\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "best_model = DecisionTreeRegressor(labelCol=\"Quantity\", featuresCol=\"features\", maxBins=4000)\n",
    "\n",
    "# Create a pipeline for staging the processes\n",
    "pipeline = Pipeline(stages=[country_indexer, stock_code_indexer, assembler, best_model])\n",
    "\n",
    "# Training the model\n",
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "277a69d0-7dcb-4f14-aba9-7f07ed26fd66",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2770,
    "lastExecutedAt": 1711380060213,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "model.save(\"best_model\")"
   },
   "outputs": [],
   "source": [
    "model.save(\"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eebd469-15b6-4282-a2a1-83d73aa690ac",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 26,
    "lastExecutedAt": 1711380256938,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pickle\nimport threading\n\n# Save the model using pickle\nmodel._lock = threading.Lock()  # Add this line to create a lock object\nwith open(\"best_model.pkl\", \"wb\") as f:\n    pickle.dump(model, f)"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39m_lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()  \u001b[38;5;66;03m# Add this line to create a lock object\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import threading\n",
    "\n",
    "# Save the model using pickle\n",
    "model._lock = threading.Lock()  # Add this line to create a lock object\n",
    "with open(\"best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "053229bf-d97e-4846-8338-4f71a7fed8ab",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 178,
    "lastExecutedAt": 1711380121253,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Stop the Spark session\n\nspark.stop()"
   },
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
